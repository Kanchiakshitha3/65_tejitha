# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IdwXCGwfFrtlo-WF0pWL366CUgk_gY6_
"""

import zipfile

zip_file_path = '/content/archive (6).zip'

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall('.')

print(f"Contents of {zip_file_path} extracted successfully.")

import os

# List all files and directories in the current working directory
files_in_current_directory = os.listdir('.')

print("Files in the current directory after extraction:")
for file_name in files_in_current_directory:
    print(file_name)

import pandas as pd

# List of identified CSV files
csv_files = [
    '11 march 2025.csv',
    'budget_data.csv',
    'budjet (2).csv'
]

# Inspect each CSV file
for file in csv_files:
    print(f"\n--- Inspecting {file} ---")
    try:
        df = pd.read_csv(file)
        print("First 5 rows:")
        print(df.head())
        print("\nDataFrame Info:")
        df.info()
    except Exception as e:
        print(f"Error reading {file}: {e}")

df_budget = pd.read_csv('budget_data.csv')
print("DataFrame 'df_budget' loaded successfully.")
print("First 5 rows of df_budget:")
print(df_budget.head())

unique_categories = df_budget['category'].unique()
print("Unique categories in 'category' column:")
print(unique_categories)

import pandas as pd

df = pd.read_csv('budget_data.csv')
print("DataFrame 'df' loaded successfully.")
print("First 5 rows of df:")
print(df.head())

category_mapping = {
    'Restuarant': 'Food & Dining',
    'Coffe': 'Food & Dining',
    'Business lunch': 'Food & Dining',
    'Market': 'Food & Dining',
    'Transport': 'Transportation',
    'Taxi': 'Transportation',
    'Rent Car': 'Transportation',
    'Fuel': 'Transportation',
    'Clothing': 'Personal Care & Lifestyle',
    'Sport': 'Personal Care & Lifestyle',
    'Health': 'Personal Care & Lifestyle',
    'Film/enjoyment': 'Personal Care & Lifestyle',
    'joy': 'Personal Care & Lifestyle',
    'Phone': 'Utilities & Services',
    'Communal': 'Utilities & Services',
    'Motel': 'Travel & Accommodation',
    'Travel': 'Travel & Accommodation',
    'Learning': 'Business & Professional',
    'Tech': 'Business & Professional',
    'business_expenses': 'Business & Professional',
    'Other': 'Miscellaneous',
    'Events': 'Miscellaneous'
}

df['broad_category'] = df['category'].map(category_mapping)

print("First 5 rows of df with new 'broad_category' column:")
print(df.head())
print("\nValue counts for 'broad_category':")
print(df['broad_category'].value_counts())

df['date'] = pd.to_datetime(df['date'])

df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day_of_week'] = df['date'].dt.dayofweek # Monday=0, Sunday=6
df['is_weekend'] = df['day_of_week'].isin([5, 6])

print("First 5 rows of df with new date features:")
print(df.head())

y = df['broad_category']
X = df.drop(columns=['date', 'category', 'broad_category'])

print("Shape of features (X):", X.shape)
print("Shape of target (y):", y.shape)
print("First 5 rows of features (X):")
print(X.head())

X_encoded = pd.get_dummies(X, columns=['is_weekend', 'day_of_week', 'month', 'year'], drop_first=True)

print("Shape of encoded features (X_encoded):", X_encoded.shape)
print("First 5 rows of encoded features (X_encoded):")
print(X_encoded.head())

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# 1. Initialize and train a LogisticRegression model
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)
print("Logistic Regression model trained successfully.")

# 2. Make predictions on the X_test dataset
y_pred = model.predict(X_test)
print("Predictions made on the test set.")

# 3. Calculate and print the accuracy of the model on the test set
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Accuracy: {accuracy:.4f}")

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

# Scale the data to address convergence warning
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 1. Initialize and train a LogisticRegression model
# Use scaled data for training
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train_scaled, y_train)
print("Logistic Regression model trained successfully with scaled data.")

# 2. Make predictions on the scaled X_test dataset
y_pred = model.predict(X_test_scaled)
print("Predictions made on the test set.")

# 3. Calculate and print the accuracy of the model on the test set
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Accuracy (with scaled data): {accuracy:.4f}")

from sklearn.metrics import classification_report

# 4. Print a classification_report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# 5. Generate and plot a confusion matrix
fig, ax = plt.subplots(figsize=(10, 8))
ConfusionMatrixDisplay.from_estimator(model, X_test_scaled, y_test, ax=ax, cmap=plt.cm.Blues, xticks_rotation='vertical')
plt.title('Confusion Matrix for Broad Category Prediction')
plt.show()

import pandas as pd

# Ensure y_test has the same index as X_test for proper merging
y_test_reset = y_test.reset_index(drop=True)

# Combine X_test, y_test, and y_pred into a new DataFrame
df_results = X_test.reset_index(drop=True).copy() # Reset index of X_test as well for clean merge
df_results['actual_category'] = y_test_reset
df_results['predicted_category'] = y_pred

print("First 5 rows of df_results:")
print(df_results.head())
print("Shape of df_results:", df_results.shape)

import matplotlib.pyplot as plt
import seaborn as sns

# Get value counts for actual and predicted categories
actual_counts = df_results['actual_category'].value_counts().reset_index()
actual_counts.columns = ['category', 'count']
actual_counts['type'] = 'Actual'

predicted_counts = df_results['predicted_category'].value_counts().reset_index()
predicted_counts.columns = ['category', 'count']
predicted_counts['type'] = 'Predicted'

# Combine the data for plotting
comparison_df = pd.concat([actual_counts, predicted_counts])

# Create the bar plot
plt.figure(figsize=(12, 7))
sns.barplot(x='category', y='count', hue='type', data=comparison_df, palette='viridis')
plt.title('Distribution of Actual vs. Predicted Broad Categories')
plt.xlabel('Broad Category')
plt.ylabel('Number of Transactions')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Category Type')
plt.tight_layout()
plt.show()

misclassified_transactions = df_results[df_results['actual_category'] != df_results['predicted_category']]

print("First 5 rows of misclassified_transactions:")
print(misclassified_transactions.head())
print("Shape of misclassified_transactions:", misclassified_transactions.shape)

minority_categories = [
    'Business & Professional',
    'Miscellaneous',
    'Transportation',
    'Utilities & Services'
]

# Filter misclassified_transactions for the specified minority actual categories
challenging_examples = misclassified_transactions[
    misclassified_transactions['actual_category'].isin(minority_categories)
]

print("\nChallenging Misclassified Transactions (Examples):")
# Display a few examples, ensuring they are from the minority categories
print(challenging_examples.head(5))
print("\nShape of challenging_examples:", challenging_examples.shape)

selected_transaction_index = challenging_examples.index[0]
selected_transaction_features = challenging_examples.iloc[0]

print(f"Selected Transaction Details (from X_test_encoded perspective, original index: {selected_transaction_index}):")
print(selected_transaction_features)

# Retrieve the original 'category' from the main DataFrame 'df' using the original index
original_category_value = df.loc[selected_transaction_index, 'category']

print(f"\nOriginal 'category' from df for this transaction: {original_category_value}")

selected_transaction_index_2 = challenging_examples.index[1]
selected_transaction_features_2 = challenging_examples.iloc[1]

print(f"Selected Transaction Details for Example 2 (from X_test_encoded perspective, original index: {selected_transaction_index_2}):")
print(selected_transaction_features_2)

# Retrieve the original 'category' from the main DataFrame 'df' using the original index
original_category_value_2 = df.loc[selected_transaction_index_2, 'category']

print(f"\nOriginal 'category' from df for this transaction: {original_category_value_2}")

from imblearn.over_sampling import SMOTE

print("SMOTE imported successfully.")

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)

print("Shape of X_resampled:", X_resampled.shape)
print("Shape of y_resampled:", y_resampled.shape)
print("\nClass distribution of y_resampled after SMOTE:")
print(y_resampled.value_counts())

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# 1. Initialize a new LogisticRegression model
model_resampled = LogisticRegression(max_iter=1000, random_state=42)

# 2. Fit the model to the X_resampled and y_resampled data
model_resampled.fit(X_resampled, y_resampled)
print("Logistic Regression model trained successfully with SMOTE-resampled data.")

# 3. Make predictions on the X_test_scaled data
y_pred_resampled = model_resampled.predict(X_test_scaled)
print("Predictions made on the original scaled test set.")

# 4. Calculate and print the accuracy of the model on the test set
accuracy_resampled = accuracy_score(y_test, y_pred_resampled)
print(f"\nModel Accuracy (with SMOTE-resampled data): {accuracy_resampled:.4f}")

# 5. Print a classification_report
print("\nClassification Report (with SMOTE-resampled data):")
print(classification_report(y_test, y_pred_resampled))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# 1. Initialize a new LogisticRegression model with class_weight='balanced'
model_weighted = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')

# 2. Fit the model to the original scaled training data
model_weighted.fit(X_train_scaled, y_train)
print("Logistic Regression model trained successfully with class weights.")

# 3. Make predictions on the X_test_scaled data
y_pred_weighted = model_weighted.predict(X_test_scaled)
print("Predictions made on the original scaled test set.")

# 4. Calculate and print the accuracy of the model on the test set
accuracy_weighted = accuracy_score(y_test, y_pred_weighted)
print(f"\nModel Accuracy (with class weights): {accuracy_weighted:.4f}")

# 5. Print a detailed classification_report
print("\nClassification Report (with class weights):")
print(classification_report(y_test, y_pred_weighted))

"""## Explore Alternative Models

### Subtask:
Experiment with different machine learning models that are known to handle imbalanced datasets more effectively, such as Tree-based models (e.g., RandomForestClassifier, GradientBoostingClassifier) or Support Vector Machines. Specifically, implement and evaluate a RandomForestClassifier.

**Reasoning**:
To experiment with an alternative model, I will implement and evaluate a RandomForestClassifier. I will initialize it with class weights to address the data imbalance, fit it to the scaled training data, make predictions on the scaled test data, and then assess its performance using accuracy and a classification report.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1. Initialize a RandomForestClassifier model with class_weight='balanced'
model_rf = RandomForestClassifier(random_state=42, class_weight='balanced')

# 2. Fit the model to the original scaled training data
model_rf.fit(X_train_scaled, y_train)
print("RandomForestClassifier model trained successfully with class weights.")

# 3. Make predictions on the X_test_scaled data
y_pred_rf = model_rf.predict(X_test_scaled)
print("Predictions made on the original scaled test set.")

# 4. Calculate and print the accuracy of the model on the test set
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"\nRandomForestClassifier Model Accuracy (with class weights): {accuracy_rf:.4f}")

# 5. Print a detailed classification_report
print("\nClassification Report (RandomForestClassifier with class weights):")
print(classification_report(y_test, y_pred_rf))

"""**Reasoning**:
After evaluating the RandomForestClassifier using accuracy and a classification report, the next logical step is to visualize its performance with a confusion matrix, similar to how the Logistic Regression model was analyzed.


"""

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# 7. Generate and plot a confusion matrix for the RandomForestClassifier
fig, ax = plt.subplots(figsize=(10, 8))
ConfusionMatrixDisplay.from_estimator(model_rf, X_test_scaled, y_test, ax=ax, cmap=plt.cm.Blues, xticks_rotation='vertical')
plt.title('Confusion Matrix for RandomForestClassifier (Broad Category Prediction)')
plt.show()

"""## Advanced Feature Engineering

### Subtask:
Analyze the importance of existing features and consider engineering new, more discriminative features that might better capture the nuances of minority categories. This could involve creating interaction terms or leveraging external data if available.

**Reasoning**:
The first instruction is to extract and print the feature importances from the trained RandomForestClassifier (`model_rf`). This can be done using the `feature_importances_` attribute of the model and then associating them with the feature names from `X_encoded` for readability.
"""

feature_importances = model_rf.feature_importances_
feature_names = X_encoded.columns

# Create a DataFrame for better visualization
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

print("Feature Importances from RandomForestClassifier:")
print(importance_df)

# Plotting feature importances
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('RandomForestClassifier Feature Importances')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

"""### Analysis of Feature Importances and Misclassifications for New Feature Engineering

**1. Feature Importance Analysis:**

From the RandomForestClassifier, the feature importances are as follows:
- `amount`: By far the most important feature, accounting for over 52% of the model's decision-making. This suggests that the monetary value of a transaction is a primary driver in classifying its category.
- `year_2023`, `year_2024`: The year features show moderate importance, indicating that spending patterns might change across years, possibly due to economic factors or personal financial habits evolution.
- `day_of_week_X` (days of the week) and `month_X` (months): These features contribute to a lesser extent, but collectively indicate a seasonal or weekly pattern in spending. Certain days or months might be associated with specific types of transactions.
- `is_weekend_True`: This binary feature has relatively low importance, suggesting that simply being a weekend vs. weekday might not be as discriminative as the specific day of the week.

**2. Analysis of Feature Insufficiency/Misleading for Minority Classes (using `challenging_examples`):**

The previous classification reports (from both Logistic Regression and RandomForestClassifier) showed poor performance (low precision and recall) for several minority categories, specifically:
- `Business & Professional`
- `Miscellaneous`
- `Transportation`
- `Utilities & Services`
- `Travel & Accommodation`
- `Personal Care & Lifestyle`

Let's reconsider the `challenging_examples` where actual categories were misclassified, often as 'Food & Dining'.

*   **Example 1 (`original_index: 1`)**: Actual: `Miscellaneous` (Original `category`: `Market`), Predicted: `Food & Dining`. Amount: `3.4`. This transaction is from June 2023, not a weekend. The `amount` is low, which could be typical for small market purchases, but 'Market' was mapped to 'Food & Dining', creating ambiguity.
*   **Example 2 (`original_index: 7`)**: Actual: `Utilities & Services` (Original `category`: `Market`), Predicted: `Food & Dining`. Amount: `1.0`. This transaction is from June 2023, not a weekend. Again, a low `amount` and 'Market' leading to misclassification.

The core issue seems to be that `amount`, while highly important, might not be sufficient to distinguish between categories, especially when some original categories (`Market`) are broadly grouped into 'Food & Dining' but can sometimes represent purchases that would align with 'Miscellaneous' or 'Utilities & Services' if we had more context. For instance, a small `amount` at a 'Market' could be for food, or it could be for a household item (Miscellaneous) or paying a small bill (Utilities & Services) if the market is a general store. The current features (amount, year, month, day_of_week, is_weekend) do not provide this deeper contextual information.

**3. Proposed New Features:**

Based on this analysis, the following new, more discriminative features could be engineered:

a. **Interaction Terms for `amount` and `day_of_week` / `month`:**
   - `amount_per_weekday`: `amount` * (1 - `is_weekend`). This might highlight spending patterns that are distinctly non-weekend related for business or utility expenses.
   - `amount_times_month_sin/cos`: To capture cyclical patterns of spending throughout the year more smoothly than one-hot encoding months.

b. **Categorical `amount` Bins:**
   - `amount_bin`: Create bins for `amount` (e.g., 'small', 'medium', 'large', 'very_large'). A very small `amount` might distinguish certain utility payments or incidental expenses from typical 'Food & Dining' transactions. For example, amounts below $5 might represent distinct types of 'Miscellaneous' or 'Utilities' expenses, or a coffee, rather than a full meal.

c. **Frequency/Recency Features (requires transaction history per user, not available in this dataset):**
   - `days_since_last_transaction_in_category`: How long since the last transaction in the *predicted* category. High frequency in 'Food & Dining' for example.
   - `avg_amount_in_category_last_N_days`: Average spending in a category over a recent period.

d. **Time-of-Day Features (if `date` column had time, which it does):**
   - `hour_of_day`: Extract the hour from the `date` column. `Business & Professional` might be more common during work hours, `Food & Dining` during meal times, etc.
   - `is_late_night`: A binary flag for transactions occurring between, say, 1 AM and 5 AM, which could indicate specific types of 'Miscellaneous' or 'Travel' expenses.

e. **Contextual Keyword Matching (if original `category` names were more descriptive):**
   - If the original 'category' column had more detailed free-text descriptions, we could use NLP techniques to extract keywords and create new features (e.g., 'fuel' from 'Transport', 'hotel' from 'Travel & Accommodation'). However, our `category` column is already quite granular, but some, like 'Other', could benefit from more detailed parsing if available.

**4. Leveraging External Data (Hypothetical):**

a. **Holidays/Special Events:**
   - **Feature**: `is_holiday`, `days_to_holiday`. If external data on public holidays, long weekends, or local events were integrated, it could help distinguish `Travel & Accommodation`, `Personal Care & Lifestyle` (e.g., entertainment), or `Miscellaneous` (e.g., gift purchases) from regular spending. For example, `Travel & Accommodation` might spike around national holidays.

b. **Economic Indicators:**
   - **Feature**: `monthly_inflation_rate`, `average_gas_price`. External economic data could influence `amount` for categories like `Transportation` (fuel costs) or general `Food & Dining` expenses due to inflation, potentially providing better context for larger-than-expected amounts in certain categories. This is more relevant for predicting *amount* rather than *category* directly, but might inform trends.

c. **Location Data (if available):**
   - **Feature**: `distance_from_home/work`, `type_of_merchant_location`. If geo-location data were available (e.g., from a mobile app), it could be highly discriminative. For instance, `Business & Professional` expenses might occur near offices, `Travel & Accommodation` further from home, etc.

For this specific dataset, the most promising new features to engineer would be `hour_of_day` and `amount_bin`, as these can be derived directly from existing columns and might add crucial granularity that `amount` alone doesn't provide.

**Reasoning**:
Based on the analysis of feature importances and misclassifications, I will now engineer new features: `hour_of_day` from the `date` column and `amount_bin` by categorizing the `amount` column. This aligns with the subtask's goal of creating more discriminative features from existing data.
"""

import numpy as np

# Create 'hour_of_day' feature
df['hour_of_day'] = df['date'].dt.hour

# Create 'amount_bin' feature by binning the 'amount'
# Define bins and labels for the 'amount' feature
bins = [0, 5, 20, 100, np.inf]
labels = ['small', 'medium', 'large', 'very_large']
df['amount_bin'] = pd.cut(df['amount'], bins=bins, labels=labels, right=True, include_lowest=True)

print("First 5 rows of df with new features 'hour_of_day' and 'amount_bin':")
print(df.head())
print("\nValue counts for 'amount_bin':")
print(df['amount_bin'].value_counts())

"""**Reasoning**:
After engineering the new features ('hour_of_day' and 'amount_bin'), I need to re-define the feature set `X` to include these new features. Then, I will apply one-hot encoding to the categorical features within `X` (including the newly added ones) to prepare the data for model training. This is a crucial step to incorporate the engineered features into the model.


"""

y = df['broad_category']
X = df.drop(columns=['date', 'category', 'broad_category'])

# Ensure 'is_weekend' is boolean before one-hot encoding
X['is_weekend'] = X['is_weekend'].astype(bool)

print("Shape of features (X) with new features:", X.shape)
print("First 5 rows of features (X) with new features:")
print(X.head())

# Apply one-hot encoding to all categorical features, including new ones
X_encoded_new = pd.get_dummies(X, columns=['is_weekend', 'day_of_week', 'month', 'year', 'hour_of_day', 'amount_bin'], drop_first=True)

print("Shape of new encoded features (X_encoded_new):", X_encoded_new.shape)
print("First 5 rows of new encoded features (X_encoded_new):")
print(X_encoded_new.head())

"""**Reasoning**:
Now that the new features have been engineered and the data is one-hot encoded, the next step is to split the dataset into training and testing sets using the `X_encoded_new` features and `y` target. This is essential for training and evaluating a new model with the enhanced features.


"""

from sklearn.model_selection import train_test_split

X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_encoded_new, y, test_size=0.2, random_state=42, stratify=y)

print("Shape of X_train_new:", X_train_new.shape)
print("Shape of X_test_new:", X_test_new.shape)
print("Shape of y_train_new:", y_train_new.shape)
print("Shape of y_test_new:", y_test_new.shape)

"""**Reasoning**:
Before training a new model with the engineered features, it is good practice to scale the numerical features. This aligns with the previous steps where the original data was scaled using StandardScaler, and ensures consistency for potentially training other models sensitive to feature scaling.


"""

from sklearn.preprocessing import StandardScaler

# Initialize the scaler
scaler_new = StandardScaler()

# Fit and transform the new training data
X_train_new_scaled = scaler_new.fit_transform(X_train_new)

# Transform the new test data using the fitted scaler
X_test_new_scaled = scaler_new.transform(X_test_new)

print("Shape of X_train_new_scaled:", X_train_new_scaled.shape)
print("Shape of X_test_new_scaled:", X_test_new_scaled.shape)
print("New training and test data scaled successfully.")

"""## Retrain and Evaluate Model with New Features

### Subtask:
Train the RandomForestClassifier model using the newly engineered and scaled features and evaluate its performance.

**Reasoning**:
I will train a new RandomForestClassifier model using the newly engineered and scaled features, then evaluate its performance by calculating the accuracy and generating a classification report.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1. Initialize a RandomForestClassifier model with class_weight='balanced'
model_rf_new = RandomForestClassifier(random_state=42, class_weight='balanced')

# 2. Fit the model to the new scaled training data
model_rf_new.fit(X_train_new_scaled, y_train_new)
print("RandomForestClassifier model trained successfully with new features and class weights.")

# 3. Make predictions on the new scaled test data
y_pred_rf_new = model_rf_new.predict(X_test_new_scaled)
print("Predictions made on the new scaled test set.")

# 4. Calculate and print the accuracy of the model on the test set
accuracy_rf_new = accuracy_score(y_test_new, y_pred_rf_new)
print(f"\nRandomForestClassifier Model Accuracy (with new features and class weights): {accuracy_rf_new:.4f}")

# 5. Print a detailed classification_report
print("\nClassification Report (RandomForestClassifier with new features and class weights):")
print(classification_report(y_test_new, y_pred_rf_new))